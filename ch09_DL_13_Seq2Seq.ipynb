{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "149d4e81de484d2b902c347bc18ffd18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a792cb2e085d4b12b1f72d878996218a",
              "IPY_MODEL_955e9bb198c4467ea5ecc94d73517d31",
              "IPY_MODEL_e9fdcf05ca54451d82a7904b4a2fccba"
            ],
            "layout": "IPY_MODEL_161c0756d4a0464290152e603dc03346"
          }
        },
        "a792cb2e085d4b12b1f72d878996218a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_655edd840fdf476f82bb4efdd50c5236",
            "placeholder": "​",
            "style": "IPY_MODEL_29bcb4a8374444deacff5d7525624689",
            "value": "epoch:1 loss:11.454045295449848:  56%"
          }
        },
        "955e9bb198c4467ea5ecc94d73517d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c325e8e588c6483584710cef9a45409a",
            "max": 3592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2902b34b77634c9c9cde7900434eefe2",
            "value": 2003
          }
        },
        "e9fdcf05ca54451d82a7904b4a2fccba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef4b76254aa7495ea6828ad72ec68942",
            "placeholder": "​",
            "style": "IPY_MODEL_b5374e8d0ff145369932f5a76f455d4e",
            "value": " 2003/3592 [00:25&lt;00:22, 69.46it/s]"
          }
        },
        "161c0756d4a0464290152e603dc03346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "655edd840fdf476f82bb4efdd50c5236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29bcb4a8374444deacff5d7525624689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c325e8e588c6483584710cef9a45409a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2902b34b77634c9c9cde7900434eefe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef4b76254aa7495ea6828ad72ec68942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5374e8d0ff145369932f5a76f455d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baejinu/deep_learning_boksoup/blob/main/ch09_DL_13_Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 불러오기"
      ],
      "metadata": {
        "id": "Ww4ZmwhFAO7I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mUWwkM-7eSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5bf860-efda-4688-9f6e-4acc3048d6da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-07 02:05:58--  https://github.com/BigData23th/Data/raw/main/corpus.txt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/corpus.txt [following]\n",
            "--2023-04-07 02:05:58--  https://raw.githubusercontent.com/BigData23th/Data/main/corpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253511 (248K) [text/plain]\n",
            "Saving to: ‘corpus.txt’\n",
            "\n",
            "corpus.txt          100%[===================>] 247.57K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-04-07 02:05:58 (50.9 MB/s) - ‘corpus.txt’ saved [253511/253511]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tab-delimited Bilingual Sentence Pairs\n",
        "# 출처 : http://www.manythings.org/anki\n",
        "!wget https://github.com/BigData23th/Data/raw/main/corpus.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 파일을 전처리\n",
        "\n",
        "import string # punctuation\n",
        "\n",
        "l = [] # 특수문자를 지운 문장들을 받아줄 리스트\n",
        "\n",
        "# with -> torch.no_grad()? => 특정한 객체가 생성이 되었을 때 with 구문이 끝나면 close 반환\n",
        "with open(\"./corpus.txt\", 'r', encoding='utf-8') as f:\n",
        "    # open(경로, 'r', encoding=인코딩방식): 파일을 읽어와줌 (텍스트파일)\n",
        "    # with .... -> 특정한 객체를 생성시키고, with 구문이 끝나면 해당 객체를 삭제 (반환)\n",
        "    # open () as f -> open을 통해 읽어들여온 파일을 f라는 이름에 변수에 할당\n",
        "    lines = f.read().split('\\n') # '\\n' = 엔터 = 개행문자\n",
        "    # 파일을 읽어온 다음에, 엔터(줄) 기준으로 쪼개줘라 -> 문장별로 리스트화\n",
        "    # lines = ['...', '...', '문장...']\n",
        "    for line in lines: # 문장\n",
        "        # 특수문자를 지우고 모든 글자를 소문자로 변경\n",
        "        txt = \"\".join(v for v in line if not v in string.punctuation).lower()\n",
        "        l.append(txt)"
      ],
      "metadata": {
        "id": "a-aQlWAjAo6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string # punctuation\n",
        "\n",
        "# l = []\n",
        "\n",
        "with open('./corpus.txt', 'r', encoding='utf-8') as f:\n",
        "    # print(f) # 불러온 파일 객체\n",
        "    # print(f.read()) # 파일 객체 -> 통으로 된 문자열\n",
        "    # print(f.read().split('\\n')) # 문자열 -> 엔터(\\n) 기준으로 분할해서 리스트화\n",
        "    # lines = f.read().split('\\n')\n",
        "    # for line in lines: # 반복문\n",
        "    #     txt = \"\".join(v for v in line if not v in string.punctuation).lower()\n",
        "    #     l.append(txt)\n",
        "    l = [\"\".join(v for v in line if not v in string.punctuation).lower()\n",
        "            for line in f.read().split('\\n')]\n",
        "l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpEobNa4eGZU",
        "outputId": "9ffc60af-fd8c-41c6-ab11-58cdfb57544e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['go\\t가',\n",
              " 'hi\\t안녕',\n",
              " 'run\\t뛰어',\n",
              " 'run\\t뛰어',\n",
              " 'who\\t누구',\n",
              " 'wow\\t우와',\n",
              " 'fire\\t쏴',\n",
              " 'help\\t도와줘',\n",
              " 'jump\\t점프',\n",
              " 'jump\\t점프해',\n",
              " 'wait\\t기다려',\n",
              " 'wait\\t잠깐',\n",
              " 'wait\\t기다려',\n",
              " 'begin\\t시작해',\n",
              " 'hello\\t안녕',\n",
              " 'i see\\t알았어',\n",
              " 'i try\\t시도해볼게',\n",
              " 'i won\\t내가 이겼어',\n",
              " 'oh no\\t아니 이런',\n",
              " 'relax\\t진정해',\n",
              " 'shoot\\t쏴',\n",
              " 'smile\\t웃어',\n",
              " 'attack\\t공격',\n",
              " 'attack\\t공격해',\n",
              " 'freeze\\t꼼짝마',\n",
              " 'get up\\t일어나',\n",
              " 'got it\\t알겠어',\n",
              " 'hug me\\t안아줘',\n",
              " 'i know\\t알아',\n",
              " 'i work\\t나 일해',\n",
              " 'listen\\t들어',\n",
              " 'no way\\t절대 아니야',\n",
              " 'no way\\t그럴리가',\n",
              " 'thanks\\t고마워',\n",
              " 'we try\\t우리는 시도할거야',\n",
              " 'we won\\t우리가 이겼어',\n",
              " 'why me\\t왜 나야',\n",
              " 'awesome\\t굉장해',\n",
              " 'be fair\\t공정하게 해',\n",
              " 'beat it\\t저리 가',\n",
              " 'call us\\t우리한테 연락해',\n",
              " 'come in\\t들어와',\n",
              " 'come on\\t어서',\n",
              " 'get out\\t나가',\n",
              " 'go away\\t저리 가',\n",
              " 'go away\\t저리 가',\n",
              " 'goodbye\\t안녕',\n",
              " 'he came\\t그가 왔어',\n",
              " 'he came\\t그 사람이 왔어',\n",
              " 'help me\\t도와줘',\n",
              " 'help me\\t도와줘',\n",
              " 'hit tom\\t톰을 때려',\n",
              " 'i agree\\t동의해',\n",
              " 'im sad\\t슬퍼',\n",
              " 'me too\\t나도',\n",
              " 'open up\\t열어',\n",
              " 'perfect\\t완벽해',\n",
              " 'show me\\t보여줘',\n",
              " 'shut up\\t시끄러워',\n",
              " 'skip it\\t건너뛰어',\n",
              " 'stop it\\t그만해',\n",
              " 'tell me\\t말해',\n",
              " 'tom won\\t톰이 이겼어',\n",
              " 'wake up\\t일어나',\n",
              " 'wash up\\t설거지 해',\n",
              " 'welcome\\t어서오세요',\n",
              " 'welcome\\t환영합니다',\n",
              " 'who won\\t누가 이겼어',\n",
              " 'why not\\t왜 안돼',\n",
              " 'cheer up\\t힘내',\n",
              " 'cool off\\t진정해',\n",
              " 'get lost\\t꺼져',\n",
              " 'go ahead\\t계속해',\n",
              " 'good job\\t잘했어',\n",
              " 'grab tom\\t톰을 잡아',\n",
              " 'how cute\\t귀엽잖아',\n",
              " 'how cute\\t이렇게 귀엽다니',\n",
              " 'how deep\\t얼마나 깊게',\n",
              " 'hurry up\\t서둘러',\n",
              " 'i forgot\\t잊어버렸어',\n",
              " 'im ugly\\t나는 못 생겼다',\n",
              " 'it hurts\\t아파',\n",
              " 'it works\\t동작하네',\n",
              " 'it works\\t작동하네',\n",
              " 'it works\\t되네',\n",
              " 'lets go\\t가자',\n",
              " 'look out\\t조심해',\n",
              " 'sit down\\t앉아',\n",
              " 'sit here\\t여기 앉아',\n",
              " 'speak up\\t크게 말해',\n",
              " 'stand up\\t일어서',\n",
              " 'tell tom\\t톰한테 말해',\n",
              " 'tell tom\\t톰에게 말해',\n",
              " 'they won\\t그들이 이겼어',\n",
              " 'they won\\t그 사람들이 이겼어',\n",
              " 'tom died\\t톰이 죽었어',\n",
              " 'tom left\\t톰이 떠났어',\n",
              " 'tom left\\t톰은 떠났어',\n",
              " 'tom lied\\t톰이 거짓말을 했어',\n",
              " 'tom lied\\t톰이 거짓말했어',\n",
              " 'tom lost\\t톰이 졌어',\n",
              " 'tom paid\\t톰이 지불했어',\n",
              " 'tom quit\\t톰이 그만둬',\n",
              " 'tom wept\\t톰이 눈물을 흘렸어',\n",
              " 'too late\\t너무 늦어',\n",
              " 'trust me\\t날 믿어',\n",
              " 'try hard\\t열심히 해',\n",
              " 'try some\\t좀 먹어봐',\n",
              " 'try this\\t이거 시도해봐',\n",
              " 'what for\\t뭐 하러',\n",
              " 'what fun\\t재밌잖아',\n",
              " 'what fun\\t이렇게 재미있을 수가',\n",
              " 'who died\\t누가 죽었어',\n",
              " 'who quit\\t누가 그만둬',\n",
              " 'answer me\\t대답해',\n",
              " 'birds fly\\t새가 날고 있네',\n",
              " 'calm down\\t진정해',\n",
              " 'come here\\t여기로 와',\n",
              " 'come home\\t집에 와',\n",
              " 'dogs bark\\t개가 짖네',\n",
              " 'dont lie\\t거짓말 하지 마',\n",
              " 'dont lie\\t거짓말 하지 마세요',\n",
              " 'fantastic\\t끝내주네',\n",
              " 'follow me\\t따라와',\n",
              " 'forget it\\t잊어버려',\n",
              " 'forget me\\t날 잊어',\n",
              " 'forget me\\t날 잊어버려',\n",
              " 'get ready\\t준비해',\n",
              " 'good luck\\t행운을 빌어',\n",
              " 'good luck\\t잘 되길 바라',\n",
              " 'grab this\\t저걸 움켜쥐어',\n",
              " 'hands off\\t손대지 마',\n",
              " 'he smiled\\t그 사람은 미소지었어',\n",
              " 'hold this\\t저걸 잡고 있어',\n",
              " 'how awful\\t끔찍해라',\n",
              " 'how awful\\t이렇게 끔찍할 수가',\n",
              " 'i fainted\\t나는 기절했어',\n",
              " 'i laughed\\t나는 웃었어',\n",
              " 'i promise\\t약속할게',\n",
              " 'im sorry\\t미안해',\n",
              " 'im sorry\\t미안해요',\n",
              " 'im sorry\\t죄송합니다',\n",
              " 'im sorry\\t유감입니다',\n",
              " 'it rained\\t비가 왔어',\n",
              " 'it rained\\t비가 내렸어',\n",
              " 'it snowed\\t눈이 왔어',\n",
              " 'it stinks\\t냄새나',\n",
              " 'its 745\\t지금 7시 45분이야',\n",
              " 'kill them\\t그들을 죽여라',\n",
              " 'leave now\\t당장 떠나',\n",
              " 'of course\\t물론이지',\n",
              " 'of course\\t물론이죠',\n",
              " 'oh please\\t아 제발',\n",
              " 'read this\\t이걸 읽어',\n",
              " 'say hello\\t인사해',\n",
              " 'see below\\t아래를 봐',\n",
              " 'seriously\\t진심이야',\n",
              " 'sit there\\t거기 앉아',\n",
              " 'sit tight\\t잠자코 있어',\n",
              " 'start now\\t당장 시작해',\n",
              " 'stay calm\\t침착해',\n",
              " 'stay here\\t여기에 있어',\n",
              " 'step back\\t물러서',\n",
              " 'stop here\\t여기서 멈춰',\n",
              " 'take care\\t주의하세요',\n",
              " 'take this\\t가져',\n",
              " 'take this\\t이거 가져',\n",
              " 'take this\\t이걸 가져',\n",
              " 'thank you\\t고마워',\n",
              " 'then what\\t그래서',\n",
              " 'they left\\t그들이 떠났어',\n",
              " 'they left\\t그 사람들은 떠났어',\n",
              " 'they left\\t그들은 떠났어',\n",
              " 'they lied\\t그들이 거짓말 쳤어',\n",
              " 'they lost\\t그들이 졌어',\n",
              " 'they lost\\t그 사람들이 졌어',\n",
              " 'tom cried\\t톰은 울었어',\n",
              " 'tom dozed\\t톰이 꾸벅 졸았어',\n",
              " 'tom drove\\t톰이 운전했어',\n",
              " 'tom knits\\t톰이 뜨개질 하고 있어',\n",
              " 'tom knows\\t톰은 알고 있어',\n",
              " 'try again\\t다시 한 번 해봐',\n",
              " 'turn left\\t왼쪽으로 돌아',\n",
              " 'turn left\\t좌회전해',\n",
              " 'wait here\\t여기서 기다려',\n",
              " 'watch out\\t조심해',\n",
              " 'we talked\\t우린 서로 얘기했어',\n",
              " 'we waited\\t우린 기다렸어',\n",
              " 'well done\\t잘 했어',\n",
              " 'who cares\\t누가 신경써',\n",
              " 'who knows\\t누가 알아',\n",
              " 'wonderful\\t멋져',\n",
              " 'you idiot\\t이 바보야',\n",
              " 'you tried\\t가상해',\n",
              " 'all aboard\\t모두 타',\n",
              " 'ask anyone\\t누군가에게 물어봐',\n",
              " 'be careful\\t조심해',\n",
              " 'be patient\\t참아',\n",
              " 'be patient\\t인내심을 가져',\n",
              " 'birds sing\\t새가 노래하네',\n",
              " 'bring wine\\t와인 가져와',\n",
              " 'bring wine\\t와인을 가져와',\n",
              " 'carry this\\t이거 날라',\n",
              " 'carry this\\t이거 운반해',\n",
              " 'check this\\t이거 확인해봐',\n",
              " 'choose one\\t하나 골라',\n",
              " 'come again\\t다시 와',\n",
              " 'come alone\\t혼자서 와',\n",
              " 'come along\\t따라와',\n",
              " 'come quick\\t빨리 와',\n",
              " 'definitely\\t절대로',\n",
              " 'dont talk\\t말하지 마',\n",
              " 'eat slowly\\t천천히 먹어',\n",
              " 'face facts\\t진실을 마주해',\n",
              " 'fire burns\\t불타네',\n",
              " 'follow him\\t저 사람을 따라가',\n",
              " 'forget tom\\t톰은 잊어버려',\n",
              " 'forget him\\t그 사람에 대해선 잊어 버려',\n",
              " 'forgive me\\t날 용서해',\n",
              " 'forgive us\\t우릴 용서해 줘',\n",
              " 'forgive us\\t우리를 용서해 줘',\n",
              " 'god exists\\t신은 존재해',\n",
              " 'he is nice\\t걔 괜찮아',\n",
              " 'he is tall\\t그 사람은 키가 커',\n",
              " 'hey relax\\t이봐 진정해',\n",
              " 'hold still\\t가만히 있으세요',\n",
              " 'hold still\\t가만히 있어',\n",
              " 'how lovely\\t어찌나 사랑스러운지',\n",
              " 'how tragic\\t너무 슬퍼',\n",
              " 'how tragic\\t이렇게나 슬프다니',\n",
              " 'hows work\\t일은 잘 되니',\n",
              " 'hows work\\t일은 어때',\n",
              " 'hurry back\\t빨리 와',\n",
              " 'i am human\\t나는 인간이야',\n",
              " 'i chuckled\\t난 킬킬 웃었어',\n",
              " 'i disagree\\t난 반대야',\n",
              " 'i envy him\\t그 사람이 부러워',\n",
              " 'i envy you\\t네가 부러워',\n",
              " 'i felt bad\\t난 기분이 나빴다',\n",
              " 'i remember\\t기억하고 있어',\n",
              " 'i want tom\\t난 톰을 원해',\n",
              " 'ignore tom\\t톰은 무시해',\n",
              " 'ignore him\\t그 사람은 무시해',\n",
              " 'is tom ill\\t톰은 아파',\n",
              " 'is that ok\\t괜찮은 거예요',\n",
              " 'it is warm\\t따뜻해',\n",
              " 'keep going\\t계속 가고 있어봐',\n",
              " 'keep quiet\\t조용히 해',\n",
              " 'keep still\\t계속 조용히 하고 있어봐',\n",
              " 'let me die\\t나 좀 죽게 내버려둬',\n",
              " 'look there\\t저기를 봐',\n",
              " 'love hurts\\t사랑은 아프다',\n",
              " 'mama cried\\t엄마가 울었어',\n",
              " 'mama cried\\t엄마는 울었어',\n",
              " 'never mind\\t신경쓰지마',\n",
              " 'no comment\\t할 말이 없어',\n",
              " 'no problem\\t문제 없어',\n",
              " 'once again\\t한 번 더',\n",
              " 'please sit\\t앉아 줘',\n",
              " 'please sit\\t제발 앉아',\n",
              " 'quiet down\\t조용히 해',\n",
              " 'sing along\\t따라 불러',\n",
              " 'start here\\t여기서 시작해',\n",
              " 'start over\\t다시 해',\n",
              " 'step aside\\t옆으로 비켜',\n",
              " 'stop lying\\t거짓말 그만 쳐',\n",
              " 'study hard\\t열심히 공부해',\n",
              " 'that hurts\\t아파',\n",
              " 'that hurts\\t그거 아프네',\n",
              " 'tom agreed\\t톰이 동의했어',\n",
              " 'tom cheats\\t톰이 사기 쳐',\n",
              " 'tom danced\\t톰은 춤을 췄어',\n",
              " 'tom drives\\t톰은 운전할 수 있어',\n",
              " 'tom failed\\t톰이 실패했어',\n",
              " 'tom forgot\\t톰이 잊었어',\n",
              " 'tom fought\\t톰이 싸웠어',\n",
              " 'tom gasped\\t톰이 헉 소리를 냈어',\n",
              " 'tom helped\\t톰이 도와줬어',\n",
              " 'tom jumped\\t톰이 점프했어',\n",
              " 'tom looked\\t톰이 쳐다봤어',\n",
              " 'tom moaned\\t톰이 끙끙댔어',\n",
              " 'tom nodded\\t톰이 고개를 끄덕였어',\n",
              " 'tom sighed\\t톰은 한숨 쉬었어',\n",
              " 'tom smiled\\t톰이 웃었어',\n",
              " 'tom snores\\t톰은 코를 골아',\n",
              " 'tom waited\\t톰은 기다렸어',\n",
              " 'tom yawned\\t톰이 하품했어',\n",
              " 'turn right\\t오른쪽으로 돌아',\n",
              " 'turn right\\t우회전해',\n",
              " 'you called\\t불렀어',\n",
              " 'you called\\t불렀니',\n",
              " 'you decide\\t네가 정해',\n",
              " 'anyone home\\t누구 집에 있어',\n",
              " 'anyone hurt\\t누군가 다쳤어',\n",
              " 'be cheerful\\t활기차게 해',\n",
              " 'be yourself\\t너 자신이 돼',\n",
              " 'be yourself\\t너답게 있어',\n",
              " 'boys do cry\\t남자애도 운다',\n",
              " 'check again\\t다시 확인해',\n",
              " 'come aboard\\t외국으로 와',\n",
              " 'come closer\\t가까이 와',\n",
              " 'come inside\\t안으로 들어와',\n",
              " 'finish this\\t이걸 끝내',\n",
              " 'get serious\\t진지하게 해',\n",
              " 'he chuckled\\t그 사람 킬킬 웃었어',\n",
              " 'he resigned\\t그 사람은 은퇴했어',\n",
              " 'how curious\\t정말 흥미로운데',\n",
              " 'how strange\\t참 이상하네',\n",
              " 'i dont lie\\t나는 거짓말 하지 않습니다',\n",
              " 'i dont lie\\t난 거짓말 안해',\n",
              " 'i dont lie\\t나는 거짓말 하지 않아',\n",
              " 'i exercised\\t난 운동했어',\n",
              " 'i overslept\\t나는 늦잠잤어',\n",
              " 'im nervous\\t긴장돼요',\n",
              " 'im nervous\\t떨려요',\n",
              " 'im shocked\\t충격이야',\n",
              " 'ignore that\\t그건 무시해',\n",
              " 'its a pity\\t안타까워요',\n",
              " 'its unfair\\t이건 불공평해',\n",
              " 'keep moving\\t계속 움직이고 있어봐',\n",
              " 'keep trying\\t계속 시도해',\n",
              " 'look around\\t둘러봐',\n",
              " 'money talks\\t돈이 최고야',\n",
              " 'my dog died\\t내 개는 죽었어',\n",
              " 'nice timing\\t타이밍 좋네',\n",
              " 'nice timing\\t좋은 타이밍이야',\n",
              " 'nobody came\\t아무도 안왔어',\n",
              " 'nobody died\\t아무도 안 죽었어',\n",
              " 'nobody died\\t아무도 죽지 않았어',\n",
              " 'nobody lied\\t아무도 거짓말을 안 했어',\n",
              " 'nobody lied\\t아무도 거짓말을 하지 않았어',\n",
              " 'plants grow\\t식물이 자란다',\n",
              " 'please sing\\t노래 부탁해',\n",
              " 'please stay\\t제발 남아 있어줘',\n",
              " 'please stop\\t제발 멈춰',\n",
              " 'release him\\t그 사람을 놓아 줘',\n",
              " 'release him\\t그를 놓아 줘',\n",
              " 'remember it\\t기억해',\n",
              " 'say goodbye\\t작별인사해',\n",
              " 'say nothing\\t아무 말도 하지 마',\n",
              " 'stop crying\\t그만 울어',\n",
              " 'stop moving\\t움직이지 마',\n",
              " 'they danced\\t그들은 춤췄어',\n",
              " 'they danced\\t그 사람들은 춤을 췄어',\n",
              " 'they hugged\\t그 사람들은 서로 포옹했어',\n",
              " 'they kissed\\t그 사람들 서로 키스했어',\n",
              " 'they obeyed\\t그 사람들은 복종했어',\n",
              " 'they smiled\\t그들이 웃었어',\n",
              " 'they smiled\\t그 사람들이 웃었어',\n",
              " 'tom blushed\\t톰의 얼굴이 빨개졌어',\n",
              " 'tom cheated\\t톰이 사기 쳤어',\n",
              " 'tom cheated\\t톰이 속임수를 썼어',\n",
              " 'tom clapped\\t톰이 박수쳤어',\n",
              " 'tom clapped\\t톰이 박수를 쳤어',\n",
              " 'tom coughed\\t톰은 기침했어',\n",
              " 'tom drowned\\t톰이 익사했어',\n",
              " 'tom drowned\\t톰이 물에 빠져 죽었어',\n",
              " 'tom escaped\\t톰이 빠져나갔어',\n",
              " 'tom escaped\\t톰이 빠져나왔어',\n",
              " 'tom exhaled\\t톰이 숨을 내쉬었어',\n",
              " 'tom exhaled\\t톰이 날숨을 쉬었어',\n",
              " 'tom fainted\\t톰이 기절했어',\n",
              " 'tom frowned\\t톰은 얼굴을 찡그렸어',\n",
              " 'tom giggled\\t톰이 피식 웃었어',\n",
              " 'tom giggled\\t톰이 낄낄거렸어',\n",
              " 'tom giggled\\t톰이 키득거렸어',\n",
              " 'tom grinned\\t톰이 씩 웃었어',\n",
              " 'tom grinned\\t톰이 씨익 웃었어',\n",
              " 'tom groaned\\t톰이 앓는 소리를 했어',\n",
              " 'tom inhaled\\t톰이 숨을 들이마셨어',\n",
              " 'tom kneeled\\t톰이 무릎을 꿇었어',\n",
              " 'tom laughed\\t톰이 웃었어',\n",
              " 'toms lying\\t톰은 거짓말 치고 있어',\n",
              " 'turn around\\t돌아',\n",
              " 'walk slowly\\t천천히 걸어',\n",
              " 'we promised\\t우린 약속했어',\n",
              " 'we remember\\t우린 기억하고 있어',\n",
              " 'we survived\\t우리가 살아남았어',\n",
              " 'whats that\\t저건 뭐야',\n",
              " 'work slowly\\t쉬엄쉬엄 일해',\n",
              " 'youre mine\\t넌 내 거야',\n",
              " 'youre mine\\t당신은 나의 것입니다',\n",
              " 'anybody here\\t누구 있어',\n",
              " 'anybody home\\t누구 집에 있어',\n",
              " 'anybody home\\t집에 누군가 있어',\n",
              " 'anybody hurt\\t누가 다쳤어',\n",
              " 'anything new\\t새로운 것이라도 있어',\n",
              " 'be realistic\\t현실적으로 생각해',\n",
              " 'beef please\\t쇠고기요',\n",
              " 'blood is red\\t피는 붉다',\n",
              " 'can i go now\\t이제 가도 되나요',\n",
              " 'come forward\\t앞쪽으로 와',\n",
              " 'come quickly\\t빨리 와',\n",
              " 'come quickly\\t빨리 오세요',\n",
              " 'dont eat it\\t먹지 마',\n",
              " 'drive faster\\t빨리 운전해',\n",
              " 'examine them\\t이것들 조사해봐',\n",
              " 'examine this\\t이걸 조사해봐',\n",
              " 'fish please\\t물고기요',\n",
              " 'ghosts exist\\t유령은 존재해',\n",
              " 'grab a spoon\\t숟가락 집어',\n",
              " 'he succeeded\\t그 사람이 성공했어',\n",
              " 'hes too old\\t그 사람은 너무 늙었어',\n",
              " 'how annoying\\t이렇게 짜증날 수가',\n",
              " 'how annoying\\t이렇게나 짜증나다니',\n",
              " 'how arrogant\\t이렇게나 건방지다니',\n",
              " 'how horrible\\t이렇게나 끔찍하다니',\n",
              " 'i apologized\\t난 사과했어',\n",
              " 'i dont know\\t나는 몰라요',\n",
              " 'i hate liars\\t난 거짓말쟁이가 싫어',\n",
              " 'i need money\\t돈이 필요해요',\n",
              " 'i understand\\t이해해',\n",
              " 'i understood\\t이해했어',\n",
              " 'im addicted\\t난 중독자야',\n",
              " 'im bleeding\\t나 피나',\n",
              " 'is that okay\\t괜찮은 거예요',\n",
              " 'is this mine\\t이거 내꺼니',\n",
              " 'is this wine\\t이게 와인이야',\n",
              " 'itll be hot\\t더워질거야',\n",
              " 'its suicide\\t자살입니다',\n",
              " 'its too old\\t그건 너무 낡았어',\n",
              " 'its too old\\t그건 너무 오래되었어',\n",
              " 'just keep it\\t그냥 그거 가져',\n",
              " 'keep dancing\\t계속 춤춰',\n",
              " 'keep dancing\\t계속 춤추고 있어봐',\n",
              " 'keep digging\\t계속 땅 파고 있어봐',\n",
              " 'keep digging\\t계속 땅 파',\n",
              " 'keep driving\\t계속 운전하고 있어봐',\n",
              " 'keep focused\\t계속 집중하고 있어봐',\n",
              " 'keep looking\\t계속 보고 있어봐',\n",
              " 'keep reading\\t계속 읽어',\n",
              " 'keep singing\\t계속 노래하고 있어',\n",
              " 'keep singing\\t계속 노래해',\n",
              " 'keep smiling\\t계속 미소지어',\n",
              " 'keep smiling\\t계속 웃어',\n",
              " 'keep smiling\\t계속 웃고 있어봐',\n",
              " 'keep talking\\t계속 말해',\n",
              " 'keep talking\\t계속 말하고 있어봐',\n",
              " 'move quietly\\t조용히 움직여',\n",
              " 'nobody asked\\t아무도 안 물어봤어',\n",
              " 'nobody knows\\t아무도 몰라',\n",
              " 'please hurry\\t서둘러 주세요',\n",
              " 'please leave\\t제발 떠나 줘',\n",
              " 'please relax\\t제발 진정해',\n",
              " 'please smile\\t웃어줘',\n",
              " 'she was busy\\t그는 바빴다',\n",
              " 'someone came\\t누군가 왔어',\n",
              " 'stop reading\\t그만 읽어',\n",
              " 'stop smoking\\t담배 피지 마',\n",
              " 'stop staring\\t그만 쳐다봐',\n",
              " 'stop talking\\t그만 말해',\n",
              " 'stop whining\\t그만 흐느껴',\n",
              " 'stop yelling\\t그만 소리쳐',\n",
              " 'they escaped\\t그 사람들은 도망 쳤어',\n",
              " 'they laughed\\t그 사람들 웃었어',\n",
              " 'they refused\\t그 사람들은 거절했어',\n",
              " 'they relaxed\\t그 사람들은 진정했어',\n",
              " 'tom answered\\t톰이 대답했어',\n",
              " 'tom approved\\t톰이 승낙했어',\n",
              " 'tom chuckled\\t톰이 싱긋 웃었어',\n",
              " 'tom chuckled\\t톰이 빙그레 웃었어',\n",
              " 'tom enlisted\\t톰이 입대했어',\n",
              " 'tom finished\\t톰이 끝냈어',\n",
              " 'tom flinched\\t톰이 움찔했어',\n",
              " 'tom grumbled\\t톰이 궁시렁거렸어',\n",
              " 'tom grumbled\\t톰이 투덜거렸어',\n",
              " 'tom insisted\\t톰이 주장했어',\n",
              " 'tom is eager\\t톰은 열성적이야',\n",
              " 'tom is quick\\t톰은 빨라',\n",
              " 'tom is quick\\t톰은 날렵해',\n",
              " 'tom is silly\\t톰은 실없어',\n",
              " 'tom is sober\\t톰은 제정신이야',\n",
              " 'tom is sober\\t톰은 멀쩡해',\n",
              " 'tom listened\\t톰이 듣고 있었어',\n",
              " 'tom shrugged\\t톰이 어깨를 으쓱했어',\n",
              " 'tom whistled\\t톰이 휘파람 불었어',\n",
              " 'unbelievable\\t설마',\n",
              " 'we apologize\\t우리가 사과할게',\n",
              " 'we dont lie\\t우리는 거짓말을 하지 않아요',\n",
              " 'we dont lie\\t우린 거짓말 안해',\n",
              " 'we overslept\\t우린 늦잠잤어',\n",
              " 'we succeeded\\t우린 성공했어',\n",
              " 'we succeeded\\t우리는 성공했어',\n",
              " 'were inside\\t우리 안에 들어와 있어',\n",
              " 'were inside\\t우린 안에 있어요',\n",
              " 'welcome back\\t어서 와',\n",
              " 'welcome home\\t어서와',\n",
              " 'what is that\\t저것은 무엇입니까',\n",
              " 'any questions\\t질문 있어',\n",
              " 'any questions\\t아무 질문이라도',\n",
              " 'can i ask why\\t이유를 물어봐도 돼',\n",
              " 'cats are cute\\t고양이는 귀여워',\n",
              " 'come tomorrow\\t내일 와',\n",
              " 'eat something\\t뭔가 먹어',\n",
              " 'everyone dies\\t누구나 죽어',\n",
              " 'flowers bloom\\t꽃이 피네',\n",
              " 'grab the rope\\t로프를 잡으세요',\n",
              " 'he is too old\\t그 사람은 너무 늙었어',\n",
              " 'hes autistic\\t그 사람은 자폐성향이 있어',\n",
              " 'how beautiful\\t이렇게나 아름다울 수가',\n",
              " 'how wonderful\\t이렇게 멋질 수가',\n",
              " 'i am homesick\\t나 향수병 걸렸어',\n",
              " 'i cant sleep\\t잠이 와',\n",
              " 'i feel guilty\\t죄책감이 들어',\n",
              " 'i feel lonely\\t외로워',\n",
              " 'i got engaged\\t나 약혼했어',\n",
              " 'i hate myself\\t나는 내 자신이 싫어',\n",
              " 'i like horses\\t나는 말을 좋아해',\n",
              " 'i like winter\\t난 겨울이 좋아',\n",
              " 'i miss my cat\\t난 내 고양이가 그리워',\n",
              " 'i smell blood\\t피 냄새가 납니다',\n",
              " 'i use firefox\\t나는 파이어폭스를 사용해',\n",
              " 'i want to die\\t죽고 싶어요',\n",
              " 'i want to die\\t죽고 싶어',\n",
              " 'ill kill him\\t나는 그를 죽일 것이다',\n",
              " 'im at school\\t난 학교에 있어',\n",
              " 'im depressed\\t우울해',\n",
              " 'im religious\\t난 신앙이 있어',\n",
              " 'is my time up\\t내 시간 끝났어',\n",
              " 'is that blood\\t그거 피야',\n",
              " 'keep fighting\\t계속 싸워',\n",
              " 'my head hurts\\t머리가 아파요',\n",
              " 'my names tom\\t제 이름은 톰입니다',\n",
              " 'please listen\\t제발 좀 들어',\n",
              " 'quiet please\\t조용히 해줘',\n",
              " 'quit gambling\\t도박 그만해',\n",
              " 'say something\\t아무 말이나 해봐',\n",
              " 'she overslept\\t그 사람은 늦잠잤어',\n",
              " 'she was naive\\t그는 순진했다',\n",
              " 'she was young\\t그는 어렸다',\n",
              " 'show yourself\\t너의 모습을 드러내',\n",
              " 'show yourself\\t네 모습을 보여줘',\n",
              " 'speak clearly\\t분명하게 말해',\n",
              " 'start singing\\t노래 시작해',\n",
              " 'stay positive\\t긍정적으로 있어',\n",
              " 'stop babbling\\t그만 떠들어',\n",
              " 'stop fighting\\t그만 싸워',\n",
              " 'stop laughing\\t그만 웃어',\n",
              " 'stop shooting\\t총 그만 쏴',\n",
              " 'stop worrying\\t그만 걱정해',\n",
              " 'stop worrying\\t걱정 그만해',\n",
              " 'thanks anyway\\t어쨌든 고마워',\n",
              " 'thats my cat\\t저거 내 고양이야',\n",
              " 'thats my dog\\t이건 내 강아지야',\n",
              " 'thats not it\\t아니야',\n",
              " 'they screamed\\t그 사람들은 비명을 질렀어',\n",
              " 'tom confessed\\t톰이 자백했어',\n",
              " 'tom graduated\\t톰이 졸업했어',\n",
              " 'tom has a cat\\t톰은 고양이를 키우고 있어',\n",
              " 'tom hesitated\\t톰이 주저했어',\n",
              " 'tom hesitated\\t톰이 머뭇거렸어',\n",
              " 'tom is honest\\t톰은 정직하다',\n",
              " 'tom overslept\\t톰은 늦잠잤어',\n",
              " 'watch closely\\t가까이서 봐',\n",
              " 'we can buy it\\t이건 우리가 살 수 있어',\n",
              " 'we understand\\t우린 이해해',\n",
              " 'we want peace\\t우리는 평화를 원합니다',\n",
              " 'were too old\\t우린 너무 늙었어',\n",
              " 'you work hard\\t너는 열심히 일을 한다',\n",
              " 'apples are red\\t사과는 빨개',\n",
              " 'autumn is here\\t가을이 되었습니다',\n",
              " 'autumn is here\\t가을이 왔어요',\n",
              " 'can i help you\\t제가 좀 도와 드릴까요',\n",
              " 'cats are great\\t고양이들은 멋져',\n",
              " 'do you hear me\\t제 말이 들리세요',\n",
              " 'everybody knew\\t모두가 알고 있었어',\n",
              " 'everybody left\\t모두 떠났어',\n",
              " 'everybody lies\\t누구나 거짓말 해',\n",
              " 'everyone stood\\t모두 일어섰어',\n",
              " 'everyone stood\\t모두가 일어섰어',\n",
              " 'happy new year\\t새해 복 많이 받아',\n",
              " 'he was hard up\\t그는 돈에 쪼들리고 있었다',\n",
              " 'hello everyone\\t모두들 안녕',\n",
              " 'i dont buy it\\t못 믿어',\n",
              " 'i feel relaxed\\t마음이 편안하다',\n",
              " 'i like reading\\t독서를 좋아합니다',\n",
              " 'i like to work\\t나는 일하기 좋아해',\n",
              " 'i love lasagna\\t저는 라자냐를 좋아해요',\n",
              " 'i love my home\\t난 내 집이 좋아',\n",
              " 'i study korean\\t한국말을 공부합니다',\n",
              " 'ill find them\\t내가 찾아 볼게',\n",
              " 'im very sorry\\t정말 미안해',\n",
              " 'im very sorry\\t정말 죄송합니다',\n",
              " 'its not funny\\t안 재밌어',\n",
              " 'its so simple\\t정말 간단해',\n",
              " 'keep tom there\\t톰은 여기에 두세요',\n",
              " 'keep listening\\t계속 들어',\n",
              " 'keep searching\\t계속 찾아봐',\n",
              " 'keep searching\\t계속 찾고 있어봐',\n",
              " 'louder please\\t좀더 큰소리로 부탁해',\n",
              " 'my name is tom\\t제 이름은 톰입니다',\n",
              " 'only god knows\\t신만이 아실 것입니다',\n",
              " 'please proceed\\t진행해줘',\n",
              " 'read this book\\t이 책 읽어',\n",
              " 'read this book\\t이 책을 읽으세요',\n",
              " 'science is fun\\t과학은 재밌어',\n",
              " 'smoking stinks\\t담배 냄새 나',\n",
              " 'someone called\\t누군가 불렀어',\n",
              " 'sorry im late\\t늦어서 미안해',\n",
              " 'stop grumbling\\t그만 투덜거려',\n",
              " 'tell everybody\\t모두한테 말해',\n",
              " 'tell everybody\\t모두에게 말해',\n",
              " 'thats suicide\\t그것은 자살입니다',\n",
              " 'the cat meowed\\t고양이가 야옹하고 울었어',\n",
              " 'the ice melted\\t얼음이 녹았어',\n",
              " 'they quarreled\\t그사람들 싸웠어',\n",
              " 'ticket please\\t티켓 부탁해',\n",
              " 'tom apologized\\t톰이 사과했어',\n",
              " 'tom hates cats\\t톰은 고양이를 싫어해',\n",
              " 'tom is abusive\\t톰은 폭력적이야',\n",
              " 'tom is awesome\\t톰은 정말 멋져',\n",
              " 'tom is too old\\t톰은 너무 늙었어',\n",
              " 'tom went there\\t톰이 거기로 갔어',\n",
              " 'watch yourself\\t조심해',\n",
              " 'we need change\\t우린 변화가 필요해',\n",
              " 'we surrendered\\t우린 항복했어',\n",
              " 'we volunteered\\t우린 자원해서 했어',\n",
              " 'you look smart\\t너 똑똑해 보여',\n",
              " 'you scared tom\\t넌 톰을 무섭게 했어',\n",
              " 'youre too old\\t넌 너무 늙었어',\n",
              " 'behave yourself\\t처신 잘해',\n",
              " 'boil some water\\t물 좀 끓여',\n",
              " 'can you help me\\t저를 좀 도와 주실래요',\n",
              " 'congratulations\\t축하해',\n",
              " 'congratulations\\t축하해요',\n",
              " 'did tom do that\\t톰이 그랬대',\n",
              " 'did tom look ok\\t톰은 괜찮아 보였어',\n",
              " 'do you like rap\\t랩 좋아해요',\n",
              " 'do you like rap\\t랩 좋아해',\n",
              " 'dont lie to me\\t내게 거짓말 하지 마',\n",
              " 'dont lie to me\\t제게 거짓말 하지 마세요',\n",
              " 'dont lie to us\\t우리에게 거짓말 하지 마',\n",
              " 'dont lie to us\\t저희에게 거짓말 하지 마세요',\n",
              " 'drive carefully\\t운전 조심하세요',\n",
              " 'drive carefully\\t운전 조심해',\n",
              " 'everybody knows\\t모두가 알고 있어',\n",
              " 'everyone dreams\\t누구나 꿈을 꿔',\n",
              " 'everyone looked\\t모두들 쳐다봤어',\n",
              " 'everyone prayed\\t모두 기도했어',\n",
              " 'everyone prayed\\t모두들 기도했어',\n",
              " 'everyone smiled\\t모두들 미소지었어',\n",
              " 'everyone waited\\t모두들 기다렸어',\n",
              " 'green suits you\\t초록색이 너한테 어울려',\n",
              " 'have a good day\\t좋은하루 되세요',\n",
              " 'he came at dawn\\t그는 새벽에 왔다',\n",
              " 'he is depressed\\t그는 우울하다',\n",
              " 'he loves trains\\t그는 열차를 좋아한다',\n",
              " 'how fascinating\\t이렇게 매력적일 수가',\n",
              " 'how fascinating\\t이렇게나 매력적이라니',\n",
              " 'how interesting\\t이렇게나 흥미롭다니',\n",
              " 'i caught a cold\\t감기 걸렸어',\n",
              " 'i caught a cold\\t감기에 걸렸어',\n",
              " 'i didnt scream\\t난 비명을 지르지 않았어',\n",
              " 'i felt excluded\\t난 소외감을 느꼈어',\n",
              " 'i hate funerals\\t장례식이 싫어',\n",
              " 'i hate my voice\\t나는 내 목소리가 싫다',\n",
              " 'i know tom well\\t나는 톰을 잘 안다',\n",
              " 'i learned a lot\\t나는 많이 배웠어',\n",
              " 'i misunderstood\\t난 오해했어',\n",
              " 'i was convicted\\t나는 유죄 판결을 받았다',\n",
              " 'i work at a zoo\\t나는 동물원에서 일해',\n",
              " 'im embarrassed\\t창피해',\n",
              " 'im heartbroken\\t제 마음이 아파요',\n",
              " 'im not sulking\\t나 삐친 거 아니야',\n",
              " 'is this ethical\\t이거 윤리적이야',\n",
              " 'it doesnt hurt\\t아프지 않아',\n",
              " 'its very humid\\t상당히 습하다',\n",
              " 'keep the change\\t잔돈은 가지세요',\n",
              " 'might i come in\\t내가 들어와도 될까',\n",
              " 'my blood boiled\\t내 피가 끓었다',\n",
              " 'my cat is black\\t내 고양이는 검은색 고양이야',\n",
              " 'please continue\\t계속 해줘',\n",
              " 'she disappeared\\t그 사람이 사라졌어',\n",
              " 'she disappeared\\t그가 사라졌어',\n",
              " 'she was my boss\\t그는 내 상사였다',\n",
              " 'shes a trainee\\t그녀는 연습생이다',\n",
              " 'shes depressed\\t그녀는 우울하다',\n",
              " 'someone coughed\\t누군가 기침했어',\n",
              " 'sorry im late\\t늦어서 미안합니다',\n",
              " 'that was stupid\\t그건 멍청했어',\n",
              " 'thats a pencil\\t그거 연필이야',\n",
              " 'thats horrible\\t끔찍하네',\n",
              " 'the bag is full\\t가방이 꽉 찼습니다',\n",
              " 'the cat is lazy\\t고양이는 게을러',\n",
              " 'there was blood\\t피가 있었다',\n",
              " 'they believe me\\t그 사람들은 날 믿어',\n",
              " 'they want peace\\t그들은 평화를 원한다',\n",
              " 'they were naive\\t걔들이 순진했어',\n",
              " 'this is suicide\\t이것은 자살입니다',\n",
              " 'tom didnt vote\\t톰은 투표 안 했어',\n",
              " 'tom disappeared\\t톰이 사라졌어',\n",
              " 'tom got retired\\t톰은 은퇴했어',\n",
              " 'tom is a runner\\t톰은 달리기 선수야',\n",
              " 'tom volunteered\\t톰이 자웠했어',\n",
              " 'tom was too old\\t톰은 너무 늙었어',\n",
              " 'watch carefully\\t잘 봐',\n",
              " 'we need experts\\t우리에겐 전문가가 필요해',\n",
              " 'what time is it\\t몇시 입니까',\n",
              " 'why do we dream\\t왜 우리는 꿈을 꿔',\n",
              " 'write something\\t뭔가 써',\n",
              " 'youre a genius\\t너 천재구나',\n",
              " 'are you busy now\\t지금 바빠',\n",
              " 'are you in there\\t너 거기 있어',\n",
              " 'are you sleeping\\t자고 있어',\n",
              " 'are you studying\\t공부하고 계십니까',\n",
              " 'call this number\\t이 번호로 전화해',\n",
              " 'choose carefully\\t신중하게 골라',\n",
              " 'come immediately\\t즉시 와',\n",
              " 'do you like fish\\t생선 좋아해요',\n",
              " 'do you like fish\\t생선 좋아해',\n",
              " 'do you like fish\\t물고기 좋아하나요',\n",
              " 'do you like fish\\t물고기 좋아해',\n",
              " 'drink some water\\t물 좀 마셔',\n",
              " 'everybody smiled\\t모두 웃었어',\n",
              " 'everybody smiled\\t모두 미소지었어',\n",
              " 'everyone changes\\t누구나 바뀌어',\n",
              " 'everyone laughed\\t모두가 웃었어',\n",
              " 'give me my sword\\t내 검을 줘',\n",
              " 'give me the file\\t나한테 파일 줘',\n",
              " 'he loves singing\\t그는 노래하기를 좋아한다',\n",
              " 'her hair is long\\t그녀의 머리카락은 길어',\n",
              " 'her hair is long\\t그녀의 머리카락은 길다',\n",
              " 'here is the bill\\t여기 계산서 입니다',\n",
              " 'his face was red\\t그 사람 얼굴은 빨갰어',\n",
              " 'how embarrassing\\t이렇게 창피할 수가',\n",
              " 'i bought a horse\\t난 말 한 마리를 샀어',\n",
              " 'i dont envy you\\t난 네가 부럽지 않아',\n",
              " 'i felt very safe\\t나는 매우 안전하다고 느꼈다',\n",
              " 'i like languages\\t언어를 좋아합니다',\n",
              " 'i like languages\\t언어가 좋습니다',\n",
              " 'i lost my wallet\\t지갑을 잃어버렸어',\n",
              " 'i may be too old\\t난 너무 늙었을지도 몰라',\n",
              " 'i may be too old\\t난 아마 너무 늙었어',\n",
              " 'i missed the bus\\t버스를 놓쳤어요',\n",
              " 'i said im sorry\\t미안하다고 했잖아',\n",
              " 'i said im sorry\\t미안하다고 했잖아요',\n",
              " 'im dead serious\\t난 절대 농담하는게 아냐',\n",
              " 'im disorganized\\t나는 체계적이지 못하다',\n",
              " 'im not suicidal\\t나는 자살하고 싶지 않다',\n",
              " 'im your teacher\\t난 네 선생이다',\n",
              " 'is that a spider\\t이거 거미야',\n",
              " 'is the bank open\\t은행 문 열었어요',\n",
              " 'is the bank open\\t은행 해요',\n",
              " 'it could be true\\t진짜일 수도 있어',\n",
              " 'it was a mistake\\t그건 실수였어',\n",
              " 'its a full moon\\t보름달이야',\n",
              " 'its nearly dark\\t거의 어두워지고 있어',\n",
              " 'its really loud\\t정말 시끄럽네',\n",
              " 'listen carefully\\t주의깊게 들어',\n",
              " 'look at the moon\\t달을 봐',\n",
              " 'nobodys perfect\\t그 누구도 완벽하지 않는다',\n",
              " 'nobodys perfect\\t완벽한 사람은 없어',\n",
              " 'nothing happened\\t아무일도 없었어',\n",
              " 'she is beautiful\\t그녀는 아름답다',\n",
              " 'somebody laughed\\t누군가 웃었어',\n",
              " 'someone has died\\t누군가 죽었어',\n",
              " 'someone screamed\\t누군가 비명을 질렀어',\n",
              " 'stop apologizing\\t그만 사과해',\n",
              " 'stop complaining\\t그만 불평해',\n",
              " 'that is a pencil\\t그거 연필이야',\n",
              " 'that made me cry\\t그것 때문에 울었다',\n",
              " 'thats very kind\\t참 친절하구나',\n",
              " 'the kids love it\\t아이들이 좋아해',\n",
              " 'there arent any\\t없다',\n",
              " 'they disappeared\\t그들은 사라졌어',\n",
              " 'they disappeared\\t그 사람들은 사라졌어',\n",
              " 'theyre amateurs\\t걔네 초짜야',\n",
              " 'think about this\\t생각 좀 해봐',\n",
              " 'this is a flower\\t이건 꽃이야',\n",
              " 'this seats free\\t이 자리 비었어',\n",
              " 'tom has kids now\\t톰한텐 이제 애들이 있어',\n",
              " 'tom is a manager\\t톰은 관리자야',\n",
              " 'tom is a nominee\\t톰은 후보야',\n",
              " 'tom is an orphan\\t톰은 고아야',\n",
              " 'tom is fantastic\\t톰은 환상적이야',\n",
              " 'tom is fast too\\t톰도 빨라',\n",
              " 'tom is real busy\\t톰은 진짜 바빠',\n",
              " 'tom is worked up\\t톰은 흥분해 있다',\n",
              " 'tom isnt a liar\\t톰은 거짓말쟁이가 아니야',\n",
              " 'tom isnt skinny\\t톰은 마르지 않았다',\n",
              " 'watch me closely\\t나를 가까이서 봐',\n",
              " 'water the plants\\t식물에 물을 주세요',\n",
              " 'we cant give up\\t우린 포기할 수 없어',\n",
              " 'we cant give up\\t포기할 수 없어요',\n",
              " 'wed been warned\\t우린 경고 받았었어',\n",
              " 'what do you like\\t무엇을 좋아하세요',\n",
              " 'what do you like\\t뭘 좋아해',\n",
              " 'what do you like\\t뭐가 좋아',\n",
              " 'where is the cat\\t고양이는 어딨어',\n",
              " 'you made tom cry\\t네가 톰을 울렸어',\n",
              " 'youll regret it\\t너 후회할거야',\n",
              " 'youre shivering\\t너 떨고 있네',\n",
              " 'your plan failed\\t네 계획은 실패했어',\n",
              " 'admission is free\\t입장은 무료야',\n",
              " 'can i borrow this\\t이거 좀 빌려 줄래',\n",
              " 'can you handle it\\t잘 해낼 수 있니',\n",
              " 'champagne please\\t샴폐인 좀',\n",
              " 'champagne please\\t샴폐인 부탁해',\n",
              " 'champagne please\\t샴폐인 주세요',\n",
              " 'come and see this\\t와서 이것좀 봐',\n",
              " 'do you have proof\\t증거 있어',\n",
              " 'do you work alone\\t혼자서 일해',\n",
              " 'does tom like you\\t톰은 너 좋아해',\n",
              " 'dont be so silly\\t실없게 굴지마',\n",
              " 'dont even try it\\t시도조차 하지마',\n",
              " 'everybody laughed\\t전부 웃었어',\n",
              " 'everyone screamed\\t모두 비명을 질렀어',\n",
              " 'everyone survived\\t모두 살아남았어',\n",
              " 'everyone survived\\t모두가 살아남았어',\n",
              " 'everyone survived\\t모두들 살아남았어',\n",
              " 'exercise outdoors\\t밖에서 운동해',\n",
              " 'god bless you all\\t신의 가호가 있길',\n",
              " 'goodnight mother\\t엄마 잘자',\n",
              " 'he died yesterday\\t그는 어제 죽었어',\n",
              " 'her nails are red\\t그 사람의 손톱은 빨간색이야',\n",
              " 'i believe in love\\t난 사랑을 믿는다',\n",
              " 'i can go tomorrow\\t난 내일 갈 수 있어',\n",
              " 'i cant walk fast\\t난 빠르게 걸을 수 없어',\n",
              " 'i cant walk fast\\t난 빠른 걸음을 할 수 없어',\n",
              " 'i cant walk fast\\t난 빠른 걸음은 할 수 없어',\n",
              " 'i doubted my eyes\\t난 내 눈을 의심했어',\n",
              " 'i feel really sad\\t나 정말 슬퍼',\n",
              " 'i got up at seven\\t난 일곱 시에 일어났어',\n",
              " 'i have a headache\\t머리가 아파요',\n",
              " 'i heard tom laugh\\t난 톰이 웃는 걸 들었어',\n",
              " 'i heard tom shout\\t난 톰이 소리지르는 걸 들었어',\n",
              " 'i kicked tom hard\\t내가 톰을 세게 걷어찼어',\n",
              " 'i like watermelon\\t난 수박 좋아해',\n",
              " 'i met tom outside\\t난 톰을 밖에서 봤어',\n",
              " 'i saw tom waiting\\t톰이 기다리는 걸 봤어',\n",
              " 'i saw tom working\\t난 톰이 일하는 걸 봤어',\n",
              " 'i sent tom a text\\t난 톰한테 문자 보냈어',\n",
              " 'i shook tom awake\\t난 톰을 흔들어 깨웠어',\n",
              " 'i stole toms car\\t내가 톰의 자동차를 훔쳤어',\n",
              " 'i taught tom golf\\t난 톰한테 골프를 가르쳤어',\n",
              " 'i texted tom back\\t난 톰한테 답장했어',\n",
              " 'i told tom to lie\\t난 톰한테 거짓말 하라고 말했어',\n",
              " 'i used toms idea\\t톰의 아이디어를 썼어',\n",
              " 'i used to be poor\\t난 가난했었어',\n",
              " 'i warned you once\\t난 널 한 번 경고했어',\n",
              " 'i was intoxicated\\t술 취했었다',\n",
              " 'i was quite lucky\\t난 꽤 운이 좋았었어',\n",
              " 'i watched tom eat\\t톰이 먹는 걸 지켜봤어',\n",
              " 'i watched a movie\\t나는 영화를 봤어',\n",
              " 'i wont permit it\\t나는 그것을 허락하지 않을거야',\n",
              " 'id be devastated\\t난 피폐해질 거야',\n",
              " 'ill go by subway\\t지하철로 갈게',\n",
              " 'im a human being\\t난 인간이야',\n",
              " 'im a patient man\\t난 참을성이 있는 남자야',\n",
              " 'im a simple girl\\t저는 단순한 소녀에요',\n",
              " 'im extremely shy\\t난 극히 낯을 가려',\n",
              " 'im in charge now\\t이제 내가 책임을 지고 있다',\n",
              " 'im not an addict\\t난 중독자 아니야',\n",
              " 'ive fed the fish\\t물고기한테 먹이를 줬어',\n",
              " 'its a dictionary\\t이것은 사전이다',\n",
              " 'its just a dream\\t그냥 꿈일 뿐이야',\n",
              " 'leave me in peace\\t저를 내버려 두세요',\n",
              " 'lets play a game\\t게임 한판 하자',\n",
              " 'life is too short\\t삶은 너무 짧네',\n",
              " 'look at the clock\\t시계를 보세요',\n",
              " 'may god bless you\\t신께서 당신을 축복하시길',\n",
              " 'no music no life\\t음악이 없으면 인생도 없어',\n",
              " 'no one was killed\\t아무도 죽지 않았어',\n",
              " 'nobody is perfect\\t그 누구도 완벽하지 않는다',\n",
              " 'please reconsider\\t다시 한 번 고려해줘',\n",
              " 'save it for later\\t나중을 위해 아껴둬',\n",
              " 'she isnt married\\t그 사람은 아직 결혼하지 않았어',\n",
              " 'she isnt married\\t그 사람은 미혼이야',\n",
              " 'she isnt married\\t그는 결혼하지 않았다',\n",
              " 'she isnt married\\t그는 미혼이다',\n",
              " 'she loves singing\\t그녀는 노래하기를 좋아한다',\n",
              " 'something changed\\t무언가 바뀌었어',\n",
              " 'stop overreacting\\t과민반응 그만해',\n",
              " 'take the medicine\\t그 약을 먹으세요',\n",
              " 'they got addicted\\t그 사람들 중독되었어',\n",
              " 'theyre all liars\\t너희 모두 거짓말쟁이다',\n",
              " 'tom hates spiders\\t톰은 거미를 싫어해',\n",
              " 'tom is a bit late\\t톰이 좀 늦네',\n",
              " 'tom is not a liar\\t톰은 거짓말쟁이가 아니야',\n",
              " 'tom made mary mad\\t톰은 메리를 화나게 했어',\n",
              " 'tom moves quickly\\t톰은 빨리 움직이네',\n",
              " 'tom seemed sleepy\\t톰은 졸려 보였어',\n",
              " 'tom vomited blood\\t톰은 피를 토했다',\n",
              " 'tom won the match\\t톰은 경기에서 이겼다',\n",
              " 'turn on the radio\\t라디오를 켜세요',\n",
              " 'we only take cash\\t우리는 현금만 가져갈 거야',\n",
              " 'what a tacky idea\\t참으로 조잡한 발상이네',\n",
              " 'whats this smell\\t이거 무슨 냄새지',\n",
              " 'where is the bank\\t그 은행은 어디에 있어요',\n",
              " 'where is the bank\\t그 은행은 어디 있어',\n",
              " 'why are you lying\\t왜 거짓말 하는거야',\n",
              " 'you are beautiful\\t아름다우시네요',\n",
              " 'you can have mine\\t너는 내 것을 가질 수 있다',\n",
              " 'youll get lonely\\t넌 외로워질거야',\n",
              " 'youre both liars\\t너희 둘 다 거짓말쟁이다',\n",
              " 'your lips are red\\t네 입술 빨개',\n",
              " 'a cat is not human\\t고양이는 인간이 아니야',\n",
              " 'ask tom for advice\\t톰에게 조언을 구해봐',\n",
              " 'can i see this one\\t이것 좀 보여주실래요',\n",
              " 'dont be so greedy\\t그렇게 욕심부리지 마',\n",
              " 'dont get me wrong\\t오해하지 마',\n",
              " 'drink to my health\\t건강을 위해 건배',\n",
              " 'everyone hesitated\\t모두 주저했어',\n",
              " 'everything changed\\t모든 것이 변했어',\n",
              " 'everything stopped\\t모든 것이 멈췄어',\n",
              " 'excuse me a minute\\t잠깐 실례합니다',\n",
              " 'he kept me waiting\\t그는 나를 기다리게 했다',\n",
              " 'i baked tom a cake\\t나는 톰에게 케이크를 구워줬다',\n",
              " 'i didnt know that\\t그건 몰랐어요',\n",
              " 'i dont understand\\t이해가 안돼',\n",
              " 'i feel very guilty\\t나는 큰 죄책감을 느끼고 있어',\n",
              " 'i have a black dog\\t나는 검은색 강아지를 키우고 있어',\n",
              " 'i have to go alone\\t난 혼자서 가야해',\n",
              " 'i knew i would win\\t내가 이길 거라는 걸 알고 있었어',\n",
              " 'i love red parrots\\t난 빨간색 앵무새가 좋아',\n",
              " 'i love this school\\t난 이 학교를 좋아해',\n",
              " 'i need to warn tom\\t나는 톰에게 경고해야 해',\n",
              " 'i often read books\\t저는 자주 책을 읽습니다',\n",
              " 'i really like snow\\t나는 눈이 정말 좋아요',\n",
              " 'i really like snow\\t난 눈이 정말 좋아',\n",
              " 'i tried not to cry\\t난 울지 않으려고 노력했어',\n",
              " 'i tried not to cry\\t나는 울지 않으려고 했다',\n",
              " 'i want to be happy\\t나는 행복해지고 싶어',\n",
              " 'i wanted red shoes\\t빨간색 신발을 원했어',\n",
              " 'i was born in 2013\\t난 2013년에 태어났어',\n",
              " 'i wasnt even here\\t난 심지어 여기에 없었어',\n",
              " 'i wasnt even here\\t난 심지어 여기 없었어',\n",
              " 'ill be there soon\\t곧 갈게',\n",
              " 'im like my father\\t나는 우리 아빠같아',\n",
              " 'im like my father\\t나는 우리 아빠를 닮았어',\n",
              " 'im still a member\\t난 아직도 회원이야',\n",
              " 'im very depressed\\t난 아주 우울해',\n",
              " 'ive caught a cold\\t감기 걸렸어',\n",
              " 'is that real blood\\t그거 진짜 피야',\n",
              " 'it must be a virus\\t이건 틀림없이 바이러스야',\n",
              " 'it was toms fault\\t이건 톰 탓이야',\n",
              " 'lets move the bed\\t침대를 옮기자',\n",
              " 'life is a delusion\\t인생은 허상이야',\n",
              " 'life is never easy\\t사는게 쉽지가 않아',\n",
              " 'no one believed me\\t아무도 날 믿지 않았어',\n",
              " 'return immediately\\t즉시 돌아와',\n",
              " 'she has small feet\\t그녀는 발이 작다',\n",
              " 'some water please\\t물 좀 주세요 제발',\n",
              " 'something happened\\t무언가 일어났어',\n",
              " 'something happened\\t무언가 생겼어',\n",
              " 'stop looking at me\\t나좀 그만 봐',\n",
              " 'thats unavoidable\\t그건 피할 수 없어',\n",
              " 'the light went out\\t전등이 꺼졌다',\n",
              " 'the night was cold\\t그날 밤은 추웠어',\n",
              " 'the room was quiet\\t방은 조용했어',\n",
              " 'the spider is dead\\t거미가 죽었어',\n",
              " 'they have no proof\\t그들에게는 증거가 없었다',\n",
              " 'they have no proof\\t그들한텐 증거가 없어',\n",
              " 'tie your shoelaces\\t신발끈을 묶으세요',\n",
              " 'tom bought a horse\\t톰은 말을 샀어',\n",
              " 'tom could be lying\\t톰이 거짓말을 하고 있을 수 있다',\n",
              " 'tom died on monday\\t톰은 월요일에 죽었어',\n",
              " 'tom got very happy\\t톰은 아주 행복해졌어',\n",
              " 'tom has aspergers\\t톰은 아스퍼거야',\n",
              " 'tom hired a lawyer\\t톰이 변호사를 고용했어',\n",
              " 'tom hired a lawyer\\t톰은 변호사를 고용했다',\n",
              " 'tom is a rough man\\t톰은 거친 남자야',\n",
              " 'tom is a timid kid\\t톰은 소심한 애야',\n",
              " 'tom is openminded\\t톰은 개방적이야',\n",
              " 'tom is quite a guy\\t톰은 꽤 남자다워',\n",
              " 'tom made me a cake\\t톰이 날 위해 케이크를 만들었어',\n",
              " 'tom never helps me\\t톰은 날 절대 안 도와줘',\n",
              " 'tom said hes weak\\t톰은 자신이 약하다고 말했다',\n",
              " 'tom was astonished\\t톰은 깜짝 놀랐다',\n",
              " 'tom wont be bored\\t톰은 지루해하지 않을 거야',\n",
              " 'we were retreating\\t우리는 후퇴하고 있었다',\n",
              " 'were still eating\\t우린 아직도 먹는 중이야',\n",
              " 'were still eating\\t우린 아직도 먹고 있어',\n",
              " 'weve been worried\\t계속 걱정했어',\n",
              " 'when will you come\\t언제쯤 올거야',\n",
              " 'wheres tom hiding\\t톰은 어디에 숨어 있어',\n",
              " 'whose book is this\\t이것은 누구의 책입니까',\n",
              " 'wifi is available\\t와이파이 돼',\n",
              " 'youre very astute\\t넌 참 눈치가 빠르네',\n",
              " 'am i older than you\\t내가 너보다 나이가 많아',\n",
              " 'are you still alone\\t너 아직도 혼자야',\n",
              " 'can i have this cup\\t이 컵 가져도 돼요',\n",
              " 'chivalry isnt dead\\t기사도는 죽지 않았다',\n",
              " 'do you go to school\\t학교에 다녀',\n",
              " 'do you have a house\\t집 있어요',\n",
              " 'do you like english\\t영어 좋아해요',\n",
              " 'do you like english\\t영어 좋아해',\n",
              " 'do you like cooking\\t요리 좋아해요',\n",
              " 'do you like cooking\\t요리 좋아해',\n",
              " 'do you like singing\\t노래하는 거 좋아해요',\n",
              " 'do you like singing\\t노래하는 거 좋아해',\n",
              " 'dont you like cats\\t고양이를 좋아하지 않아',\n",
              " 'dreams do come true\\t꿈은 이루어질 거야',\n",
              " 'everybody loves her\\t모두 그녀를 사랑한다',\n",
              " 'everybody loves him\\t모두가 그를 사랑한다',\n",
              " 'everythings normal\\t모든 것이 정상이야',\n",
              " 'hes in his fifties\\t그 사람은 오십 대야',\n",
              " 'his dream came true\\t그 사람의 꿈은 실현되었어',\n",
              " 'how may i serve you\\t어떻게 도와드릴까요',\n",
              " 'i acted like a fool\\t나는 바보같이 굴었어',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l[:5] #\\t - 탭"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0UBQQi0DBiF",
        "outputId": "439f7df7-b5e7-40cf-c564-9bf731fc60dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['go\\t가', 'hi\\t안녕', 'run\\t뛰어', 'run\\t뛰어', 'who\\t누구']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습용 데이터 만들기"
      ],
      "metadata": {
        "id": "9uJ7SQ2xDNlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 단어가 10개를 넘지 않는 문장들만 사용\n",
        "* 문장을 불러올 때 <EOS(End Of Speech)> 토큰을 추가해서 문장이 끝났음을 알림"
      ],
      "metadata": {
        "id": "8amudxBvDUcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.utils.data.dataset import Dataset"
      ],
      "metadata": {
        "id": "Tp5Ac8oiDn24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BOW를 만드는 함수 정의"
      ],
      "metadata": {
        "id": "vFh4bwZ8DoOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_BOW(corpus): # 말뭉치 -> 문장 -> BOW를 만드는 함수\n",
        "    BOW = {\"<SOS>\": 0, \"<EOS>\": 1}\n",
        "    # BOW 안에 문장의 시작과 끝을 알리는\n",
        "    # SOS(Start Of Speech) 토큰과 EOS(End Of Speech) 토큰을 추가\n",
        "\n",
        "    # 문장 내 단어들을 사용하여 BOW를 생성\n",
        "    for line in corpus:\n",
        "        for word in line.split():\n",
        "            if word not in BOW.keys(): # 등록되지 않은 단어면\n",
        "                BOW[word] = len(BOW.keys())\n",
        "                # 사전에 추가해주는데, 해당 단어의 고유번호는 이전까지의 키의 갯수\n",
        "    return BOW"
      ],
      "metadata": {
        "id": "WrQ7qjwYD05b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습용 데이터셋 정의"
      ],
      "metadata": {
        "id": "zD_EagauE2fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Eng2Kor(Dataset):\n",
        "    def __init__(self, path='./corpus.txt') -> None:\n",
        "        super().__init__()\n",
        "        self.eng_corpus = [] # 영어문장이 들어가는 변수\n",
        "        self.kor_corpus = [] # 한글문장이 들어가는 변수\n",
        "\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            lines = f.read().split('\\n')\n",
        "            for line in lines: # 문장\n",
        "                txt = \"\".join(v for v in line\n",
        "                              if not v in string.punctuation).lower()\n",
        "                # \\t 구분이 되어 있었음 (영어와 한글) -> 탭을 기준으로 분리\n",
        "                engtxt, kortxt = txt.split('\\t') # 0 : 영어 # 1 : 한글\n",
        "                # engtxt = txt.split('\\t')[0]\n",
        "                # kortxt = txt.split('\\t')[1]\n",
        "\n",
        "                # 길이가 10 이하인 문장 = 단어의 갯수가 10개 이하인 문장만 학습\n",
        "                if len(engtxt.split()) <= 10 and len(kortxt.split()) <= 10:\n",
        "                    # 영어, 한글 번역문 모두 10개 단어 이하인 데이터만 사용\n",
        "                    self.eng_corpus.append(engtxt)\n",
        "                    self.kor_corpus.append(kortxt)\n",
        "        \n",
        "        # 영어와 한글 문장을 각각 BOW(단어 사전)으로 변환\n",
        "        self.engBOW = get_BOW(self.eng_corpus)\n",
        "        self.korBOW = get_BOW(self.kor_corpus)\n",
        "    \n",
        "    # 문장을 단어별로 분리하는 함수\n",
        "    def gen_seq(self, line): # line = 문장\n",
        "        seq = line.split() # 토큰화 한다음에\n",
        "        seq.append(\"<EOS>\") # 마지막에 EOS(문장 끝) 토큰 추가\n",
        "        return seq\n",
        "\n",
        "    def __len__(self): # 데이터의 개수를 반환하는 함수\n",
        "        return len(self.eng_corpus)\n",
        "\n",
        "    # 데이터와 정답을 반환하는 함수\n",
        "    def __getitem__(self, i): # data, label을 지정\n",
        "        # 문자열로 되어 있는 문장을 숫자 표현으로 변경\n",
        "        # 1) 영어 corpus 중 i번째 문장을 받아옴\n",
        "        # 2) gen_seq -> i번째 문장을 seq 형태로 변환 (토큰+EOS)\n",
        "        # 3) 단어 사전을 사용해서 고유번호 형태로 변환 (학습을 위해 숫자형태로 변환)\n",
        "        data = np.array([\n",
        "            self.engBOW[txt] for txt in self.gen_seq(self.eng_corpus[i])\n",
        "        ])\n",
        "        label = np.array([\n",
        "            self.korBOW[txt] for txt in self.gen_seq(self.kor_corpus[i])\n",
        "        ])\n",
        "        return data, label # 영어 데이터 (입력) -> 한글 데이터 (정답)"
      ],
      "metadata": {
        "id": "jFiIQebMEwD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 로더"
      ],
      "metadata": {
        "id": "7hyu5o55qrQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loader(dataset): # 데이터셋의 문장을 한 문장씩 불러오기 위한 함수 정의\n",
        "    for i in range(len(dataset)):\n",
        "        data, label = dataset[i]\n",
        "\n",
        "        # 데이터와 정답을 반환\n",
        "        yield torch.tensor(data), torch.tensor(label)\n",
        "        # yield : 리턴과 유사, 값을 반복적으로 반환"
      ],
      "metadata": {
        "id": "8_zGEJvFqrBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 정의"
      ],
      "metadata": {
        "id": "UPINig5DrTOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인코더 정의\n",
        "* 임베딩층, GRU층"
      ],
      "metadata": {
        "id": "za-92TOSrXSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size) -> None:\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # 임베딩층\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        # GRU층\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        # nn.GRU : GRU 계산. input_size, hidden_size, num_layers)\n",
        "    \n",
        "    def forward(self, x, h): # x: 입력값 / h : 은닉상태\n",
        "        # 배치 차원과 시계열 차원 추가\n",
        "        x = self.embedding(x).view(1, 1, -1)\n",
        "        output, hidden = self.gru(x, h) # output : 문장의 특성, hidden 은닉 상태\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "003BAHh4rehb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 디코더 정의\n",
        "* 임베딩 층\n",
        "* 전결합 층 (ReLU)\n",
        "* 전결합 층 (Softmax)\n",
        "* 내적\n",
        "* GRU층"
      ],
      "metadata": {
        "id": "wNA-b81Itgjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=11) -> None:\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        # 임베딩 층 정의\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "        # 어텐션 가중치를 계산하기 위한 MLP층\n",
        "        self.attention = nn.Linear(hidden_size * 2, max_length)\n",
        "        # 10개 + <EOS>(1) = 최대 길이 11개\n",
        "\n",
        "        # 특징 추출을 위한 MLP층\n",
        "        self.context = nn.Linear(hidden_size * 2, hidden_size)\n",
        "\n",
        "        # 오버피팅을 피하기 위한 드롭아웃층\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        # GRU층\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "        # 단어 분류를 위한 MLP층\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # 활성화 함수\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        # LogSoftmax(dim) : 소프트맥스 함수에 로그 값을 취한 것을 반환\n",
        "        # dim -> 계산의 대상이 될 차원값\n",
        "    \n",
        "    def forward(self, x, h, encoder_outputs): # x : 입력값, h : 은닉상태, e...: 인코더 결과값\n",
        "        # 입력 받은 x(현 시점의 디코더 입력)을 임베딩 층을 사용해 밀집 표현으로 변환\n",
        "        # 배치 차원, 시계열 차원, 단어들.\n",
        "        x = self.embedding(x).view(1, 1, -1)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # 어텐션 가중치 계산\n",
        "        attn_weights = self.softmax(\n",
        "            self.attention(torch.cat((x[0], h[0]), -1))\n",
        "        )\n",
        "\n",
        "        # 어텐션 가중치와 인코더의 출력을 내적(크기가 다른 두 배열을 방향이 일치하는 만큼 곱함)\n",
        "        attn_applied = torch.bmm(\n",
        "            attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0)\n",
        "        ) # bmm(A, B) : A 크기가 (B, N, M)이고, B 크기가 (B, M, K)\n",
        "        # => (B, N, K) 크기의 출력을 반환 -> 유사도.\n",
        "        # (얼마나 어텐션 가중치 - 이전까지의 전체 맥락\n",
        "        # -> 인코더 출력 (인코더를 통해서 구한 핵심 내용)) 과의 일치도가 어느정도냐?)\n",
        "\n",
        "        # 인코더 각 시점의 중요도와 밀집 표현을 합쳐서 MLP층으로 특징 추출\n",
        "        output = torch.cat((x[0], attn_applied[0]), 1)\n",
        "        output = self.context(output).unsqueeze(0)\n",
        "        output = self.relu(output)\n",
        "        # 인코더의 중요도(attn_applied)와 현시점에서의 디코더의 밀집표현(x)을 합쳐서\n",
        "        # MLP층(context)으로 입력\n",
        "        # -> MP층은 인코더 각 시점의 중요도와 현시점 디코더의 밀집표현을 동시에 처리\n",
        "        # -> 인코더의 중요도가 디코더의 반영\n",
        "\n",
        "        # GRU층으로 입력\n",
        "        output, hidden = self.gru(output, h)\n",
        "\n",
        "        # 예측된 단어를 출력\n",
        "        output = self.out(output[0])\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "CDqJvnMJtX11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 정의"
      ],
      "metadata": {
        "id": "IOuGn4jC44GK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습에 필요한 요소 정의"
      ],
      "metadata": {
        "id": "CyiuJmmk47HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "# 학습에 사용할 프로세서 정의\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "# 학습에 사용할 데이터셋\n",
        "dataset = Eng2Kor()\n",
        "\n",
        "# 인코더 디코더 정의\n",
        "encoder = Encoder(input_size=len(dataset.engBOW), hidden_size=64).to(device)\n",
        "decoder = Decoder(64, len(dataset.korBOW), dropout_p=0.1).to(device)\n",
        "# 인코더와 디코더 학습을 위한 최적화 함수 정의\n",
        "encoder_optimizer = Adam(encoder.parameters(), lr=0.001)\n",
        "decoder_optimizer = Adam(decoder.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "42VTmT0Ps72D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qZiVal6U580O",
        "outputId": "8b56d9f4-6e53-4c72-e8cb-a4e96723648f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 루프 정의"
      ],
      "metadata": {
        "id": "lR0tenX96W95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "    iterator = tqdm(loader(dataset), total=len(dataset))\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, label in iterator:\n",
        "        data = torch.tensor(data, dtype=torch.long).to(device)\n",
        "        label = torch.tensor(label, dtype=torch.long).to(device)\n",
        "\n",
        "        # 인코더의 초기 은닉 상태\n",
        "        encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "        # 인코더의 모든 시점의 출력을 저장하는 변수\n",
        "        # 최대 단어 10개 + 종료(EOS) -> 11개\n",
        "        encoder_outputs = torch.zeros(11, 64).to(device)\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        # 인코더 동작\n",
        "        for ei in range(len(data)): # data : 토큰화, 고유번호 -> 단어들의 리스트\n",
        "            # ei => data의 인덱스들\n",
        "            # 한 단어씩 인코더에 넣어줌\n",
        "            encoder_output, encoder_hidden = encoder(\n",
        "                data[ei], encoder_hidden)\n",
        "\n",
        "            # 인코더의 은닉상태를 저장\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "            # 1, 1, *64*\n",
        "        \n",
        "        decoder_input = torch.tensor([[0]]).to(device)\n",
        "\n",
        "        # 인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로 지정\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # 디코더 동작\n",
        "        # 티처 포싱 (Teacher Forcing: 교사 강요)\n",
        "        # Seq2Seq 구조에서 현시점의 입력을 (모델의 예측값을 사용하는 대신에) 정답을 이용하는 방법\n",
        "        # 엉뚱한 답을 피하고, 시간 단축을 위해 강제적으로 정답을 넣어주는 기술 (50% 확률로 적용)\n",
        "        use_teacher_forcing = True if random.random() < 0.5 else False\n",
        "        \n",
        "        if use_teacher_forcing:\n",
        "            for di in range(len(label)): # di : data 인덱스\n",
        "                decoder_output = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs\n",
        "                )\n",
        "\n",
        "                target = torch.tensor(label[di], dtype=torch.long).to(device)                \n",
        "                target = torch.unsqueeze(target, dim=0).to(device)\n",
        "                loss += nn.CrossEntropyLoss()(decoder_output, target)\n",
        "                \n",
        "                # 직접적으로 정답을 다음 시점의 입력으로 넣어줌\n",
        "                decoder_input = target # 바꿔치기\n",
        "        else:\n",
        "            for di in range(len(label)):\n",
        "                decoder_output = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "                target = torch.tensor(label[di], dtype=torch.long).to(device)                \n",
        "                target = torch.unsqueeze(target, dim=0).to(device)\n",
        "                loss += nn.CrossEntropyLoss()(decoder_output, target)\n",
        "\n",
        "                # 가장 높은 확률을 갖는 단어의 인덱스 topi\n",
        "                topv, topi = decoder_output.topk(1) # top k -> (1)개를 불러옴\n",
        "                \n",
        "                # 디코더의 예측값을 다음 시점의 입력으로 넣어줌\n",
        "                decoder_input = topi.squeeze().detach() # 텐서 -> 값\n",
        "                \n",
        "                if decoder_input.item() == 1: #<EOS> 토큰을 만나면 중지\n",
        "                    break\n",
        "        \n",
        "        # 전체 손실 계산\n",
        "        total_loss += loss.item() / len(dataset)\n",
        "        iterator.set_description(f\"epoch:{epoch+1} loss:{total_loss}\")\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "torch.save(encoder.state_dict(), \"attn_enc.pt\")\n",
        "torch.save(decoder.state_dict(), \"attn_dec.pt\")"
      ],
      "metadata": {
        "id": "oM5eo7gf6UrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626,
          "referenced_widgets": [
            "149d4e81de484d2b902c347bc18ffd18",
            "a792cb2e085d4b12b1f72d878996218a",
            "955e9bb198c4467ea5ecc94d73517d31",
            "e9fdcf05ca54451d82a7904b4a2fccba",
            "161c0756d4a0464290152e603dc03346",
            "655edd840fdf476f82bb4efdd50c5236",
            "29bcb4a8374444deacff5d7525624689",
            "c325e8e588c6483584710cef9a45409a",
            "2902b34b77634c9c9cde7900434eefe2",
            "ef4b76254aa7495ea6828ad72ec68942",
            "b5374e8d0ff145369932f5a76f455d4e"
          ]
        },
        "outputId": "9c79ab37-a954-4325-b0ec-ca811bd6a96b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3592 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "149d4e81de484d2b902c347bc18ffd18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-b67003997b3d>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data = torch.tensor(data, dtype=torch.long).to(device)\n",
            "<ipython-input-28-b67003997b3d>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label = torch.tensor(label, dtype=torch.long).to(device)\n",
            "<ipython-input-28-b67003997b3d>:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(label[di], dtype=torch.long).to(device)\n",
            "<ipython-input-28-b67003997b3d>:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target = torch.tensor(label[di], dtype=torch.long).to(device)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-b67003997b3d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attn_enc.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 state_steps)\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    282\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_state_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0mdevice_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/BigData23th/Data/raw/main/attn_enc.pt\n",
        "!wget https://github.com/BigData23th/Data/raw/main/attn_dec.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAsM-EwPDLgl",
        "outputId": "b79c56e1-93c1-4145-d5ae-a4fb2f485e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-07 03:42:29--  https://github.com/BigData23th/Data/raw/main/attn_enc.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/attn_enc.pt [following]\n",
            "--2023-04-07 03:42:29--  https://raw.githubusercontent.com/BigData23th/Data/main/attn_enc.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 727147 (710K) [application/octet-stream]\n",
            "Saving to: ‘attn_enc.pt.1’\n",
            "\n",
            "attn_enc.pt.1       100%[===================>] 710.10K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2023-04-07 03:42:29 (85.8 MB/s) - ‘attn_enc.pt.1’ saved [727147/727147]\n",
            "\n",
            "--2023-04-07 03:42:29--  https://github.com/BigData23th/Data/raw/main/attn_dec.pt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/attn_dec.pt [following]\n",
            "--2023-04-07 03:42:30--  https://raw.githubusercontent.com/BigData23th/Data/main/attn_dec.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2857305 (2.7M) [application/octet-stream]\n",
            "Saving to: ‘attn_dec.pt.1’\n",
            "\n",
            "attn_dec.pt.1       100%[===================>]   2.72M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-04-07 03:42:30 (233 MB/s) - ‘attn_dec.pt.1’ saved [2857305/2857305]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 성능 평가"
      ],
      "metadata": {
        "id": "Xj6sqB6TDZFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더 가중치 불러오기\n",
        "encoder.load_state_dict(torch.load(\"attn_enc.pt\", map_location=device))\n",
        "decoder.load_state_dict(torch.load(\"attn_dec.pt\", map_location=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-See_gDDSvg",
        "outputId": "d3c8e43c-3a30-4ff2-a582-58adf20baf42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 불러올 영어 문장을 랜덤하게 지정\n",
        "idx = random.randint(0, len(dataset))\n",
        "# 테스트에 사용할 문장\n",
        "input_sentence = dataset.eng_corpus[idx]\n",
        "input_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "axp4313pDnt7",
        "outputId": "40181377-037e-43ee-ebd8-92cea4f62bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'im just watching television'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망이 번역한 문장\n",
        "pred_sentence = \"\""
      ],
      "metadata": {
        "id": "2KR-fniJD-9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, label = dataset[idx]\n",
        "data = torch.tensor(data, dtype=torch.long).to(device) # 영어문장\n",
        "label = torch.tensor(label, dtype=torch.long).to(device) # 한국어문장"
      ],
      "metadata": {
        "id": "wpQit4YVEGvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxAVPvZcEbZl",
        "outputId": "68493a32-36cd-4dc2-89bf-baa7dda61ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  54,  346, 1509, 1510,    1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr73uVzPEXEp",
        "outputId": "7c421ba2-78ba-4df8-a6c0-3d6ecd1c451d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 273,  489, 2851,  497,  155,    1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인코더 동작"
      ],
      "metadata": {
        "id": "mTYzESGiEtfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더의 초기 은닉 상태 정의\n",
        "encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "# 인코더 출력을 담기 위한 변수\n",
        "encoder_outputs = torch.zeros(11, 64).to(device)"
      ],
      "metadata": {
        "id": "_WwZLartEu1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ei in range(len(data)):\n",
        "    # 한 단어씩 인코더에 넣어줌\n",
        "    encoder_output, encoder_hidden = encoder(\n",
        "        data[ei], encoder_hidden\n",
        "    )\n",
        "    # 인코더의 출력을 저장\n",
        "    encoder_outputs[ei] = encoder_output[0, 0]"
      ],
      "metadata": {
        "id": "13okMEhfE6K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_outputs"
      ],
      "metadata": {
        "id": "Bumb4Mr1FP8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 디코더 동작"
      ],
      "metadata": {
        "id": "4JsCvUSrFMaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더 초기 입력\n",
        "decoder_input = torch.tensor([[0]]).to(device)\n",
        "# 0 -> 문장이 시작되었다는 SOS 토큰\n",
        "\n",
        "# 인코더의 마지막 은닉 상태 -> 디코더의 초기 은닉 상태\n",
        "decoder_hidden = encoder_hidden"
      ],
      "metadata": {
        "id": "YtbFVngTFN5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for di in range(11):\n",
        "    # 디코더 모델을 통해서 단어별 나올 확률\n",
        "    decoder_output = decoder(\n",
        "        decoder_input, decoder_hidden, encoder_outputs\n",
        "    )\n",
        "    # 가장 높은 확률을 갖는 단어의 요소 계산\n",
        "    topv, topi = decoder_output.topk(1)\n",
        "    # 가장 높은 확률의 단어\n",
        "    decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    # EOS 토큰을 만나면 중지\n",
        "    if decoder_input.item() == 1:\n",
        "        break\n",
        "    \n",
        "    # 예측 문자열에 가장 높은 확률의 단어를 추가\n",
        "    pred_sentence += list(dataset.korBOW.keys())[decoder_input] + \" \"\n",
        "\n",
        "print(input_sentence)\n",
        "print(pred_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRyfeY8OFjuB",
        "outputId": "0fd8ed6e-64bf-4670-e09d-8fc8e50a34c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "im just watching television\n",
            "난 책을 티비를 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 통합"
      ],
      "metadata": {
        "id": "uQdzZcLYJi11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts -q"
      ],
      "metadata": {
        "id": "5NyU4tGQKhrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "# 학습에 사용할 프로세서 정의\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "# 학습에 사용할 데이터셋\n",
        "dataset = Eng2Kor()\n",
        "\n",
        "# 인코더 디코더 정의\n",
        "encoder = Encoder(input_size=len(dataset.engBOW), hidden_size=64).to(device)\n",
        "decoder = Decoder(64, len(dataset.korBOW), dropout_p=0.1).to(device)\n",
        "\n",
        "# 인코더 가중치 불러오기\n",
        "encoder.load_state_dict(torch.load(\"attn_enc.pt\", map_location=device))\n",
        "# 디코더 가중치 불러오기\n",
        "decoder.load_state_dict(torch.load(\"attn_dec.pt\", map_location=device))\n",
        "\n",
        "idx = random.randint(0, len(dataset))\n",
        "# 테스트에 사용할 문장\n",
        "input_sentence = dataset.eng_corpus[idx]\n",
        "# 신경망이 번역한 문장\n",
        "pred_sentence = \"\"\n",
        "\n",
        "data, label = dataset[idx]\n",
        "data = torch.tensor(data, dtype=torch.long).to(device)\n",
        "label = torch.tensor(label, dtype=torch.long).to(device)\n",
        "\n",
        "encoder_hidden = torch.zeros(1, 1, 64).to(device)\n",
        "encoder_outputs = torch.zeros(11, 64).to(device)\n",
        "\n",
        "for ei in range(len(data)):\n",
        "   encoder_output, encoder_hidden = encoder(\n",
        "       data[ei], encoder_hidden)\n",
        "     \n",
        "   encoder_outputs[ei] = encoder_output[0, 0]  \n",
        "\n",
        "decoder_input = torch.tensor([[0]]).to(device)\n",
        "\n",
        "decoder_hidden = encoder_hidden \n",
        "\n",
        "for di in range(11):\n",
        "   decoder_output = decoder(\n",
        "                       decoder_input, decoder_hidden, encoder_outputs)\n",
        "   topv, topi = decoder_output.topk(1)\n",
        "   decoder_input = topi.squeeze().detach()\n",
        "\n",
        "   if decoder_input.item() == 1:  \n",
        "       break\n",
        "\n",
        "   pred_sentence += list(dataset.korBOW.keys())[decoder_input] + \" \"  \n",
        "\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from time import sleep\n",
        "\n",
        "file_name = '/content/sample.mp3'\n",
        "\n",
        "text = input_sentence\n",
        "tts_en = gTTS(text=text)\n",
        "tts_en.save(file_name)\n",
        "\n",
        "print(input_sentence)  # 영어 문장\n",
        "wn = Audio(file_name, autoplay=True)\n",
        "display(wn)\n",
        "\n",
        "sleep(4)\n",
        "\n",
        "text = pred_sentence\n",
        "tts_ko = gTTS(text=text, lang='ko')\n",
        "tts_ko.save(file_name)\n",
        "print(pred_sentence)  # 한글 문장\n",
        "\n",
        "wn = Audio(file_name, autoplay=True)\n",
        "display(wn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "OmQ0IotPJkF_",
        "outputId": "f00ad8c0-6f26-4ec5-ad5f-2809841be45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "only four horses competed in the race\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오직 네 마리 말만 경주에 참가했어 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}